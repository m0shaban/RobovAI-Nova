from typing import Dict, Any
from .base import BaseTool
from backend.core.llm import llm_client
from backend.core.config import settings

# --- Voice & Audio Tools ---

class VoiceNoteTool(BaseTool):
    @property
    def name(self): return "/voice_note"
    @property
    def description(self): return "ØªØ­ÙˆÙŠÙ„ ÙÙˆÙŠØ³ Ù†ÙˆØª Ù„Ù†Øµ + Ø±Ø¯ Ø°ÙƒÙŠ"
    @property
    def cost(self): return 5
    
    async def execute(self, user_input: str, user_id: str) -> Dict[str, Any]:
        """
        ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Groq Whisper API
        user_input: Ø¥Ù…Ø§ Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø£Ùˆ base64
        """
        import httpx
        
        if not user_input or len(user_input) < 5:
            return {
                "status": "success", 
                "output": "ğŸ¤ Ø§Ø³ØªØ®Ø¯Ù… Ø²Ø± Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©",
                "tokens_deducted": 0
            }
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Groq API Key
        if not settings.GROQ_API_KEY:
            return {
                "status": "error",
                "output": "âŒ Groq API Key ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯",
                "tokens_deducted": 0
            }
        
        try:
            # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù…Ù„Ù Ø­Ù‚ÙŠÙ‚ÙŠ (Ù…Ù† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©)
            if user_input.endswith('.webm') or user_input.endswith('.wav') or '/' in user_input or '\\' in user_input:
                # Ù…Ø³Ø§Ø± Ù…Ù„Ù
                async with httpx.AsyncClient(timeout=30.0) as client:
                    with open(user_input, 'rb') as audio_file:
                        files = {
                            'file': ('audio.webm', audio_file, 'audio/webm')
                        }
                        data = {
                            'model': 'whisper-large-v3-turbo',
                            'language': 'ar',
                            'response_format': 'json',
                            'temperature': 0.0
                        }
                        headers = {
                            'Authorization': f'Bearer {settings.GROQ_API_KEY}'
                        }
                        
                        response = await client.post(
                            'https://api.groq.com/openai/v1/audio/transcriptions',
                            files=files,
                            data=data,
                            headers=headers
                        )
                        
                        if response.status_code == 200:
                            result = response.json()
                            transcribed_text = result.get('text', '')
                            
                            # Ø±Ø¯ Ø°ÙƒÙŠ
                            reply_prompt = f"Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù‚Ø§Ù„: '{transcribed_text}'. Ø±Ø¯ Ø¹Ù„ÙŠÙ‡ Ø¨ÙˆØ¯."
                            reply = await llm_client.generate(reply_prompt, provider="auto")
                            
                            output = f"""ğŸ¤ **ØªØ­ÙˆÙŠÙ„ Ù†Ø§Ø¬Ø­!**

ğŸ“ **Ø§Ù„Ù†Øµ:** {transcribed_text}

ğŸ’¬ **Ø§Ù„Ø±Ø¯:** {reply}"""
                        else:
                            output = f"âŒ Ø®Ø·Ø£ Whisper: {response.status_code}\n{response.text}"
            
            else:
                # Ù†Øµ Ø¹Ø§Ø¯ÙŠ
                output = await llm_client.generate(user_input, provider="auto")
            
            return {"status": "success", "output": output, "tokens_deducted": self.cost}
            
        except Exception as e:
            return {
                "status": "error",
                "output": f"âŒ Ø®Ø·Ø£: {str(e)}",
                "tokens_deducted": 0
            }


class TtsCustomTool(BaseTool):
    @property
    def name(self): return "/tts_custom"
    @property
    def description(self): return "ØªØ­ÙˆÙŠÙ„ Ù†Øµ Ù„ØµÙˆØª Ø¨ØµÙˆØªÙƒ Ø§Ù„Ø®Ø§Øµ"
    @property
    def cost(self): return 5
    
    async def execute(self, user_input: str, user_id: str) -> Dict[str, Any]:
        # user_input format: "Text to speak | Voice sample URL"
        # In production: Use magpie-tts-zeroshot
        parts = user_input.split("|")
        if len(parts) < 2:
            return {"status": "error", "output": "Format: Text | Voice Sample URL"}
        
        text, voice_sample = parts[0].strip(), parts[1].strip()
        
        # Simulate TTS
        return {
            "status": "success", 
            "output": f"ğŸ”Š Generated audio for: '{text}' using voice from {voice_sample}\n[Audio URL would be here in production]",
            "tokens_deducted": self.cost
        }


class CleanAudioTool(BaseTool):
    @property
    def name(self): return "/clean_audio"
    @property
    def description(self): return "ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ©"
    @property
    def cost(self): return 3
    
    async def execute(self, user_input: str, user_id: str) -> Dict[str, Any]:
        # user_input = audio URL
        # In production: nvidia/background-noise-removal + studiovoice
        return {
            "status": "success",
            "output": f"âœ¨ Enhanced audio quality for: {user_input}\n[Studio-quality audio URL would be here]",
            "tokens_deducted": self.cost
        }


class MeetingNotesTool(BaseTool):
    @property
    def name(self): return "/meeting_notes"
    @property
    def description(self): return "ØªÙØ±ÙŠØº Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹Ø§Øª + Action Items"
    @property
    def cost(self): return 10
    
    async def execute(self, user_input: str, user_id: str) -> Dict[str, Any]:
        # user_input = meeting recording URL
        # Pipeline: ASR â†’ Summarization â†’ Extract Action Items
        
        # Simulate ASR
        transcript = f"[Meeting transcript from: {user_input}]"
        
        # Summarize + Extract actions
        prompt = f"From this meeting transcript, provide:\n1. Summary\n2. Key decisions\n3. Action items\n\nTranscript: {transcript}"
        output = await llm_client.generate(
            prompt, 
            provider="nvidia",
            model=settings.NVIDIA_GENERAL_MODEL,
            system_prompt="You are a meeting assistant. Extract structured information."
        )
        
        return {"status": "success", "output": f"ğŸ“ Meeting Notes:\n\n{output}", "tokens_deducted": self.cost}
