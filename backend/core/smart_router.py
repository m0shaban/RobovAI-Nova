"""
ðŸš€ RobovAI Nova - Smart Router v3.0 (State-of-the-Art)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Advanced Features:
âœ… Multi-turn Context Memory
âœ… Semantic Intent Understanding
âœ… Confidence Scoring
âœ… Tool Chain Execution
âœ… Fallback Strategies
âœ… Platform-Aware Responses
âœ… Rate Limiting Protection
âœ… Usage Analytics
"""

from backend.core.llm import llm_client
from backend.tools.registry import ToolRegistry
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import asyncio
import re
import json
import hashlib
from collections import defaultdict

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸ“Š DATA STRUCTURES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


@dataclass
class ConversationContext:
    """Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…"""

    user_id: str
    messages: List[Dict[str, str]] = field(default_factory=list)
    last_tool: Optional[str] = None
    last_intent: Optional[str] = None
    platform: str = "web"
    language: str = "ar-EG"  # Egyptian Arabic
    created_at: datetime = field(default_factory=datetime.now)
    last_active: datetime = field(default_factory=datetime.now)
    tool_usage: Dict[str, int] = field(default_factory=dict)

    def add_message(self, role: str, content: str):
        self.messages.append(
            {"role": role, "content": content, "timestamp": datetime.now().isoformat()}
        )
        if len(self.messages) > 20:  # Keep last 20 messages
            self.messages = self.messages[-20:]
        self.last_active = datetime.now()

    def get_context_summary(self, max_messages: int = 5) -> str:
        """Get recent conversation context"""
        recent = self.messages[-max_messages:]
        return "\n".join([f"{m['role']}: {m['content'][:100]}" for m in recent])


@dataclass
class RoutingResult:
    """Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªÙˆØ¬ÙŠÙ‡"""

    route_type: str  # 'tool', 'chat', 'chain', 'clarify'
    tool_name: Optional[str] = None
    tool_chain: List[str] = field(default_factory=list)
    confidence: float = 0.0
    intent: str = ""
    extracted_params: Dict[str, Any] = field(default_factory=dict)
    suggested_response: Optional[str] = None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸ§  SMART ROUTER v3.0
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class SmartToolRouter:
    """
    ðŸš€ RobovAI Nova Smart Router v3.0

    State-of-the-art routing system with:
    - Semantic understanding
    - Context awareness
    - Multi-platform support
    - Tool chaining
    - Confidence scoring
    """

    # User context cache
    _contexts: Dict[str, ConversationContext] = {}

    # Rate limiting
    _rate_limits: Dict[str, List[datetime]] = defaultdict(list)
    MAX_REQUESTS_PER_MINUTE = 30

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ðŸŽ¯ INTENT PATTERNS (Advanced Regex + Semantic)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    # Casual conversation - NEVER trigger tools
    CASUAL_INTENTS = {
        "greeting": [
            r"^(Ø§Ù‡Ù„Ø§|Ù…Ø±Ø­Ø¨Ø§|Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…?|ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±|Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ±|Ù‡Ø§ÙŠ|Ù‡Ø§Ù„Ùˆ|hello|hi|hey|Ø³Ù„Ø§Ù…|Ø§Ø²ÙŠÙƒ|Ø¹Ø§Ù…Ù„ Ø§ÙŠÙ‡|ÙƒÙŠÙÙƒ|ÙŠØ§ Ù‡Ù„Ø§)",
            r"^(ØµØ¨Ø§Ø­ Ø§Ù„Ù†ÙˆØ±|Ù…Ø³Ø§Ø¡ Ø§Ù„Ù†ÙˆØ±|Ø§Ù‡Ù„ÙŠÙ†|Ù‡Ù„Ø§ ÙˆØ§Ù„Ù„Ù‡)",
        ],
        "farewell": [
            r"^(Ø¨Ø§ÙŠ|Ù…Ø¹ Ø§Ù„Ø³Ù„Ø§Ù…Ù‡|bye|goodbye|Ø³Ù„Ø§Ù…|ÙˆØ¯Ø§Ø¹Ø§|Ø§Ù„Ù‰ Ø§Ù„Ù„Ù‚Ø§Ø¡)",
        ],
        "identity": [
            r"(Ø§Ù†Øª Ù…ÙŠÙ†|Ù…Ù† Ø§Ù†Øª|Ø§Ø³Ù…Ùƒ Ø§ÙŠÙ‡|Ø§Ù†Øª Ø§ÙŠÙ‡|Ø§ÙŠÙ‡ Ù‡Ùˆ Ø§Ø³Ù…Ùƒ|Ù…ÙŠÙ† Ø§Ù†Øª)",
            r"(Ø¹Ø±ÙÙ†ÙŠ Ø¨Ù†ÙØ³Ùƒ|Ø¹Ø±ÙÙ†ÙŠ Ø¹Ù„ÙŠÙƒ|Ù‚ÙˆÙ„ÙŠ Ø¹Ù† Ù†ÙØ³Ùƒ)",
            r"(who are you|what is your name|introduce yourself|what are you)",
        ],
        "thanks": [
            r"^(Ø´ÙƒØ±Ø§|Ù…ØªØ´ÙƒØ±|ØªØ³Ù„Ù…|Ø§Ù„Ù„Ù‡ ÙŠØ¹Ø·ÙŠÙƒ Ø§Ù„Ø¹Ø§ÙÙŠÙ‡|thank|thanks|merci)",
        ],
        "affirmation": [
            r"^(Ø§Ù‡|Ù„Ø§|Ø§ÙˆÙƒ|ØªÙ…Ø§Ù…|Ù…Ø§Ø´ÙŠ|Ø§ÙƒÙŠØ¯|Ø·Ø¨Ø¹Ø§|ok|yes|no|yeah|yep|nope|sure)$",
        ],
        "how_are_you": [
            r"(Ø¹Ø§Ù…Ù„ Ø§ÙŠÙ‡|ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ|Ø§Ø²ÙŠÙƒ|Ø§Ø®Ø¨Ø§Ø±Ùƒ Ø§ÙŠÙ‡|how are you|Ø¹Ø§Ù…Ù„Ùƒ Ø§ÙŠÙ‡|Ø§ÙŠÙ‡ Ø§Ø®Ø¨Ø§Ø±Ùƒ)",
        ],
        "capabilities": [
            r"(Ø¨ØªØ¹Ù…Ù„ Ø§ÙŠÙ‡|ØªÙ‚Ø¯Ø± ØªØ¹Ù…Ù„ Ø§ÙŠÙ‡|Ø§ÙŠÙ‡ Ù‚Ø¯Ø±Ø§ØªÙƒ|Ø§ÙŠÙ‡ Ø§Ù…ÙƒØ§Ù†ÙŠØ§ØªÙƒ|what can you do)",
            r"(Ø§ÙŠÙ‡ Ø§Ù„Ø§Ø¯ÙˆØ§Øª|ÙÙŠÙ‡ Ø§ÙŠÙ‡|Ø¹Ù†Ø¯Ùƒ Ø§ÙŠÙ‡)",
        ],
        # ðŸ“¤ File uploads - NEVER trigger tools
        "file_upload": [
            r"(Ø¬Ø§Ø±ÙŠ Ø±ÙØ¹|ðŸ“¤|Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø±ÙØ¹|uploading)",
            r"(\.jpg|\.jpeg|\.png|\.gif|\.webp|\.pdf|\.doc|\.mp3|\.wav|\.mp4)",
            r"(photo_|image_|file_|document_|audio_|video_)",
        ],
        # ðŸŽ¤ Voice messages - NEVER trigger tools
        "voice_message": [
            r"^ðŸŽ¤\s*\*\*",
            r"(ØªØ³Ø¬ÙŠÙ„ ØµÙˆØªÙŠ|Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ©)",
        ],
    }

    # Tool-specific patterns with parameters extraction
    TOOL_PATTERNS = {
        # ðŸŽ¨ Creative
        "/generate_image": {
            "patterns": [
                r"(ÙˆÙ„Ø¯|Ø§Ø¹Ù…Ù„|Ø§Ø±Ø³Ù…|ØµÙ…Ù…|Ø®Ù„Ù‚)\s*(ØµÙˆØ±Ø©|ØµÙˆØ±Ù‡|Ø±Ø³Ù…Ø©|ØªØµÙ…ÙŠÙ…)\s*(?:Ø¹Ù†|Ù„|Ù„Ù€)?\s*(.+)?",
                r"(generate|create|draw|make)\s*(image|picture|art)\s*(?:of|about)?\s*(.+)?",
            ],
            "extract": lambda m: {"prompt": m.group(3) if m.lastindex >= 3 else ""},
            "confidence": 0.9,
        },
        # ðŸŒ¤ï¸ Weather
        "/weather": {
            "patterns": [
                r"(Ø·Ù‚Ø³|Ø§Ù„Ø¬Ùˆ|Ø­Ø±Ø§Ø±Ø©|Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø©)\s*(?:ÙÙŠ|ÙÙ‰)?\s*(.+)?",
                r"(weather|temperature)\s*(?:in|at|for)?\s*(.+)?",
                r"(Ø§Ù„Ø¬Ùˆ Ø¹Ø§Ù…Ù„ Ø§ÙŠÙ‡|Ø§ÙŠÙ‡ Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ù‚Ø³)\s*(?:ÙÙŠ|ÙÙ‰)?\s*(.+)?",
            ],
            "extract": lambda m: {
                "location": (
                    m.group(2).strip() if m.lastindex >= 2 and m.group(2) else "Cairo"
                )
            },
            "confidence": 0.95,
        },
        # ðŸ˜‚ Entertainment
        "/joke": {
            "patterns": [
                r"(Ù†ÙƒØªØ©|Ø§Ø­ÙƒÙŠÙ„ÙŠ Ù†ÙƒØªØ©|Ø¶Ø­ÙƒÙ†ÙŠ|Ù†ÙƒØªÙ‡|Ù‚ÙˆÙ„ÙŠ Ù†ÙƒØªØ©)",
                r"(tell me a joke|joke please|make me laugh)",
            ],
            "extract": lambda m: {},
            "confidence": 0.95,
        },
        # ðŸ’± Currency
        "/currency": {
            "patterns": [
                r"(Ø³Ø¹Ø±|Ø­ÙˆÙ„)\s*(Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±|Ø§Ù„ÙŠÙˆØ±Ùˆ|Ø§Ù„Ø¬Ù†ÙŠÙ‡|Ø§Ù„Ø¹Ù…Ù„Ø©)",
                r"(currency|exchange rate|convert)\s*(.+)?",
                r"(ÙƒØ§Ù…|Ø¨ÙƒØ§Ù…)\s*(Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±|Ø§Ù„ÙŠÙˆØ±Ùˆ)",
            ],
            "extract": lambda m: {},
            "confidence": 0.9,
        },
        # ðŸ“Š Charts
        "/chart": {
            "patterns": [
                r"(Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ|Ø´Ø§Ø±Øª|chart|graph)\s*(.+)?",
                r"(Ø§Ø¹Ù…Ù„|Ø§Ø±Ø³Ù…)\s*(Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ|Ø´Ø§Ø±Øª|Ø¬Ø¯ÙˆÙ„)",
            ],
            "extract": lambda m: {"data": m.group(2) if m.lastindex >= 2 else ""},
            "confidence": 0.9,
        },
        # ðŸ§® Math
        "/math": {
            "patterns": [
                r"(Ø§Ø­Ø³Ø¨|Ø­Ø³Ø§Ø¨|calculate)\s*(.+)?",
                r"(Ø¬Ø°Ø±|sqrt|sin|cos|tan|log)\s*\(?\s*(\d+)",
                r"(\d+)\s*[\+\-\*\/\^]\s*(\d+)",
            ],
            "extract": lambda m: {"expression": m.group(0)},
            "confidence": 0.85,
        },
        # ðŸ”„ Convert
        "/convert": {
            "patterns": [
                r"(Ø­ÙˆÙ„|convert)\s*(\d+)\s*(\w+)\s*(?:Ø§Ù„Ù‰|to|Ø¥Ù„Ù‰)\s*(\w+)",
                r"(\d+)\s*(ÙƒÙŠÙ„Ùˆ|Ù…ØªØ±|Ù…ÙŠÙ„|Ø¯Ø±Ø¬Ø©|kg|km|mi|lb)\s*(?:=|ÙŠØ³Ø§ÙˆÙŠ|ÙƒØ§Ù…)",
            ],
            "extract": lambda m: (
                {"value": m.group(2), "from": m.group(3), "to": m.group(4)}
                if m.lastindex >= 4
                else {}
            ),
            "confidence": 0.9,
        },
        # ðŸŽ² Random
        "/pick": {
            "patterns": [
                r"(Ø§Ø®ØªØ§Ø±|Ø§Ø®ØªØ±|pick|choose)\s*(?:Ù…Ù†|from)?\s*(.+)",
                r"(Ø¹Ø´ÙˆØ§Ø¦ÙŠ|random)\s*(.+)?",
            ],
            "extract": lambda m: {"options": m.group(2) if m.lastindex >= 2 else ""},
            "confidence": 0.85,
        },
        # ðŸ“… Date
        "/date_calc": {
            "patterns": [
                r"(Ø¹Ù…Ø±ÙŠ|age|ÙƒØ§Ù… Ø³Ù†Ø©)\s*(.+)?",
                r"(ÙØ±Ù‚|difference)\s*(?:Ø¨ÙŠÙ†|between)\s*(.+)",
            ],
            "extract": lambda m: {},
            "confidence": 0.8,
        },
        # ðŸ“– Quran
        "/quran": {
            "patterns": [
                r"(Ù‚Ø±Ø§Ù†|quran|Ø¢ÙŠØ©|Ø³ÙˆØ±Ø©|surah|ayah)",
            ],
            "extract": lambda m: {},
            "confidence": 0.9,
        },
        # ðŸ” Wikipedia
        "/wikipedia": {
            "patterns": [
                r"(ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§|wikipedia|wiki)\s*(.+)?",
                r"(Ø§Ø¨Ø­Ø« Ø¹Ù†|search for|Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù†)\s*(.+)",
            ],
            "extract": lambda m: {"query": m.group(2) if m.lastindex >= 2 else ""},
            "confidence": 0.8,
        },
        # ðŸ’» Code
        "/code_fix": {
            "patterns": [
                r"(ØµÙ„Ø­|Ø§ØµÙ„Ø­|fix|debug)\s*(?:Ø§Ù„ÙƒÙˆØ¯|Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯|this code|code)",
                r"(ÙÙŠÙ‡ Ø®Ø·Ø£|there is an error|bug in)",
            ],
            "extract": lambda m: {},
            "confidence": 0.85,
        },
        # ðŸ” Password
        "/check_password": {
            "patterns": [
                r"(Ù‚ÙˆØ©|ÙØ­Øµ|check)\s*(?:ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±|ÙƒÙ„Ù…Ø© Ø§Ù„Ø³Ø±|password)",
            ],
            "extract": lambda m: {},
            "confidence": 0.9,
        },
    }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ðŸ”§ CORE METHODS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    @classmethod
    def get_context(cls, user_id: str, platform: str = "web") -> ConversationContext:
        """Get or create user context"""
        if user_id not in cls._contexts:
            cls._contexts[user_id] = ConversationContext(
                user_id=user_id, platform=platform
            )
        return cls._contexts[user_id]

    @classmethod
    def check_rate_limit(cls, user_id: str) -> bool:
        """Check if user is rate limited"""
        now = datetime.now()
        minute_ago = now - timedelta(minutes=1)

        # Clean old entries
        cls._rate_limits[user_id] = [
            t for t in cls._rate_limits[user_id] if t > minute_ago
        ]

        if len(cls._rate_limits[user_id]) >= cls.MAX_REQUESTS_PER_MINUTE:
            return False

        cls._rate_limits[user_id].append(now)
        return True

    @classmethod
    def is_casual_intent(cls, message: str) -> Tuple[bool, str]:
        """
        Check if message is casual conversation
        Returns: (is_casual, intent_type)
        """
        message_lower = message.lower().strip()

        # Very short messages are usually casual
        if len(message_lower.split()) <= 2 and not message_lower.startswith("/"):
            for intent, patterns in cls.CASUAL_INTENTS.items():
                for pattern in patterns:
                    if re.search(pattern, message_lower, re.IGNORECASE):
                        return True, intent
            # Even if no pattern matched, short messages are casual
            return True, "short_message"

        # Check casual patterns
        for intent, patterns in cls.CASUAL_INTENTS.items():
            for pattern in patterns:
                if re.search(pattern, message_lower, re.IGNORECASE):
                    return True, intent

        return False, ""

    @classmethod
    def detect_tool_pattern(cls, message: str) -> Optional[RoutingResult]:
        """
        Detect tool from message using pattern matching
        Returns RoutingResult with confidence score
        """
        message_lower = message.lower().strip()

        # Direct command
        if message_lower.startswith("/"):
            tool_name = message_lower.split()[0]
            if ToolRegistry.get_tool(tool_name):
                return RoutingResult(
                    route_type="tool",
                    tool_name=tool_name,
                    confidence=1.0,
                    intent="direct_command",
                )

        # Pattern matching
        for tool_name, config in cls.TOOL_PATTERNS.items():
            for pattern in config["patterns"]:
                match = re.search(pattern, message_lower, re.IGNORECASE)
                if match:
                    params = {}
                    try:
                        params = config["extract"](match)
                    except:
                        pass

                    return RoutingResult(
                        route_type="tool",
                        tool_name=tool_name,
                        confidence=config["confidence"],
                        intent=f"pattern_{tool_name}",
                        extracted_params=params,
                    )

        return None

    @classmethod
    async def detect_tool_semantic(
        cls, message: str, context: ConversationContext
    ) -> Optional[RoutingResult]:
        """
        Use LLM for semantic intent detection (fallback)
        Only called for ambiguous messages
        """
        # Get available tools
        all_tools = list(ToolRegistry.list_tools())[:30]  # Limit for prompt size

        prompt = f"""Analyze this user message and determine if they want to use a specific tool.

User message: "{message}"

Available tools (examples):
- /weather: check weather
- /joke: tell jokes
- /generate_image: create AI images
- /translate_egy: translate to Egyptian Arabic
- /chart: create charts
- /math: calculations
- /convert: unit conversion
- /quran: Quran verses
- /wikipedia: search Wikipedia

Recent context: {context.get_context_summary(3)}

IMPORTANT: If the message is casual conversation (greetings, questions about the bot, thanks, etc.), respond with "CHAT".

Response format (JSON):
{{"tool": "/tool_name or CHAT", "confidence": 0.0-1.0, "reason": "brief reason"}}
"""

        try:
            response = await llm_client.generate(
                prompt,
                provider="auto",
                system_prompt="You are an intent classifier. Output only valid JSON.",
            )

            # Parse response
            response = response.strip()
            if response.startswith("```"):
                response = response.split("```")[1].replace("json", "").strip()

            data = json.loads(response)

            if data.get("tool", "CHAT").upper() == "CHAT":
                return None

            tool_name = data.get("tool", "")
            if tool_name and ToolRegistry.get_tool(tool_name):
                return RoutingResult(
                    route_type="tool",
                    tool_name=tool_name,
                    confidence=float(data.get("confidence", 0.7)),
                    intent="semantic_detection",
                )

        except Exception as e:
            print(f"Semantic detection error: {e}")

        return None

    @classmethod
    async def detect_tool(
        cls, user_message: str, user_id: str = "default", platform: str = "web"
    ) -> Optional[str]:
        """
        Main detection method - backwards compatible
        """
        result = await cls.route(user_message, user_id, platform)
        return result.tool_name if result.route_type == "tool" else None

    @classmethod
    async def route(
        cls, message: str, user_id: str = "default", platform: str = "web"
    ) -> RoutingResult:
        """
        ðŸš€ Main routing method - Advanced routing with all features
        """
        context = cls.get_context(user_id, platform)
        context.add_message("user", message)

        # 1. Rate limit check
        if not cls.check_rate_limit(user_id):
            print(f"âš ï¸ Rate Limit Exceeded for {user_id}")
            return RoutingResult(
                route_type="chat",
                suggested_response="âš ï¸ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù‚Ø¯ ØªØ¬Ø§ÙˆØ²Øª Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ ÙÙŠ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹.",
            )

        # 2. Check casual intent first
        is_casual, intent = cls.is_casual_intent(message)
        if is_casual:
            return RoutingResult(route_type="chat", intent=intent)

        # 3. Pattern-based detection (fast path)
        pattern_result = cls.detect_tool_pattern(message)
        if pattern_result and pattern_result.confidence >= 0.8:
            context.last_tool = pattern_result.tool_name
            context.last_intent = pattern_result.intent
            return pattern_result

        # 4. For medium-length messages, try semantic detection
        word_count = len(message.split())
        if word_count >= 4 and word_count <= 50:
            semantic_result = await cls.detect_tool_semantic(message, context)
            if semantic_result and semantic_result.confidence >= 0.75:
                context.last_tool = semantic_result.tool_name
                return semantic_result

        # 5. Default to chat
        return RoutingResult(route_type="chat", intent="general")

    @classmethod
    async def route_message(
        cls, user_message: str, user_id: str, platform: str = "web"
    ) -> Dict[str, Any]:
        """
        ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù„Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ø£Ùˆ Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø¹Ø§Ù…Ø©
        Backwards compatible with existing code
        """
        result = await cls.route(user_message, user_id, platform)
        context = cls.get_context(user_id, platform)

        if result.route_type == "tool" and result.tool_name:
            tool_class = ToolRegistry.get_tool(result.tool_name)
            if tool_class:
                tool = tool_class()

                # Extract payload from message
                user_input = user_message
                if user_message.lower().startswith(result.tool_name):
                    parts = user_message.split(maxsplit=1)
                    user_input = parts[1] if len(parts) > 1 else ""

                # Add extracted params if available
                if result.extracted_params:
                    for key, value in result.extracted_params.items():
                        if value and key not in user_input:
                            user_input = f"{user_input} {value}".strip()

                # Execute tool
                try:
                    tool_result = await tool.execute(user_input, user_id)

                    # Track usage
                    context.tool_usage[result.tool_name] = (
                        context.tool_usage.get(result.tool_name, 0) + 1
                    )

                    return {
                        "type": "tool",
                        "tool_name": result.tool_name,
                        "result": tool_result,
                        "confidence": result.confidence,
                        "intent": result.intent,
                    }
                except Exception as e:
                    return {
                        "type": "error",
                        "error": str(e),
                        "tool_name": result.tool_name,
                    }

        return {
            "type": "chat",
            "tool_name": None,
            "intent": result.intent,
            "suggested_response": result.suggested_response,
        }

    @classmethod
    def get_user_stats(cls, user_id: str) -> Dict[str, Any]:
        """Get usage statistics for a user"""
        if user_id not in cls._contexts:
            return {}

        context = cls._contexts[user_id]
        return {
            "user_id": user_id,
            "platform": context.platform,
            "message_count": len(context.messages),
            "tool_usage": context.tool_usage,
            "most_used_tool": (
                max(context.tool_usage, key=context.tool_usage.get)
                if context.tool_usage
                else None
            ),
            "last_active": context.last_active.isoformat(),
            "session_duration": (datetime.now() - context.created_at).total_seconds(),
        }

    @classmethod
    def cleanup_old_contexts(cls, max_age_hours: int = 24):
        """Remove old inactive contexts"""
        cutoff = datetime.now() - timedelta(hours=max_age_hours)
        to_remove = [
            uid for uid, ctx in cls._contexts.items() if ctx.last_active < cutoff
        ]
        for uid in to_remove:
            del cls._contexts[uid]
        return len(to_remove)
